{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all necessary helper functions and classes.\n",
    "We also define the device to run the models on (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.phishing import LoadPhishingDataset\n",
    "from models.builers.retriever import Retriever\n",
    "from data.dataloader import DataLoader\n",
    "from data.phishing import PhishingDataset\n",
    "from models.model_loader_helpers import createModels, loadModels\n",
    "from utils.phishing_utils import getPhishingQueries\n",
    "from models.DPR import DPR\n",
    "from utils.metrics_uitls import timeFunction\n",
    "from utils.phishing_utils import calculatePhishingAccuracy, evaluatePhishingByMajorityVote\n",
    "from utils.misc import batch\n",
    "import configparser\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define Experiment Configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the configuration of the experiment.\n",
    "Both the datasets to perform the experiment on and the model configurations.\n",
    "\n",
    "Change the load_saved_models variable to True, to load locally saved models, instead of creating them during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs/config.ini')\n",
    "data_loader = DataLoader(config)\n",
    "\n",
    "top_k = 25\n",
    "test_split = 0.2\n",
    "batch_size=25\n",
    "\n",
    "model_descriptions = {\n",
    "        \"TF-IDF\": {},\n",
    "        \"BM25\": {},\n",
    "        \"DPR\": {},\n",
    "        \"Crossencoder\": {\"n\":2*top_k},\n",
    "        \"KMeans\": {\"k\":3},\n",
    "        \"CURE\": {\"n\": 25,\n",
    "                \"shrinkage_fraction\" : 0.1,\n",
    "                \"threshold\": 0.25,\n",
    "                \"initial_clusters\": 50,\n",
    "                \"subsample_fraction\": 0.5,\n",
    "                \"similarity_measure\": \"cosine\"}}\n",
    "\n",
    "load_saved_models = False\n",
    "\n",
    "embedding_model_name = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"#\"bert-base-uncased\"\n",
    "embedding_index_folder_path = \"indexes\"\n",
    "phishing_dataset_path = \"data/datasets/phishing_dataset.pickle\"\n",
    "datasets_path = \"data/datasets/Phishing_Email.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define Function to Pre-compute Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function helps us reduce a lot of computations, by pre computing the embeddings offline and loading them online, instead of computing them multiple times (one time for each model that relies on embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preComputeEmbeddings(dataset: str, \n",
    "                         documents: list[dict], \n",
    "                         embedding_model_name: str, \n",
    "                         embedding_index_folder_path: str):\n",
    "    embedder = DPR(documents, model_name=embedding_model_name)\n",
    "    embedding_index_path = getPreComputedEmbeddingsPath(dataset, embedding_index_folder_path)\n",
    "    embedder.SaveIndex(embedding_index_path)\n",
    "    return embedding_index_path\n",
    "\n",
    "def getPreComputedEmbeddingsPath(dataset: str, embedding_index_folder_path: str):\n",
    "    return os.path.join(embedding_index_folder_path,dataset,\"embedding_index.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load or create Phishing Dataset\n",
    "\n",
    "This is required since unique IDs are generated for each document whenever a phishing dataset is made. Therefore, you also need to create new models that are compatible with your dataset by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatePhishingDataset(datasets_path: str, save: bool = True):\n",
    "    dataset = LoadPhishingDataset(datasets_path)\n",
    "    dataset.Shuffle()\n",
    "    if save:\n",
    "        with open(\"data/datasets/phishing_dataset.pickle\", 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "    return dataset\n",
    "\n",
    "def LoadPrecomputedPhishingDataset(phishing_dataset_path: str):\n",
    "    # with open(\"data/datasets/phishing_dataset.pickle\", 'rb') as f:\n",
    "    with open(phishing_dataset_path, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhishingData = CreatePhishingDataset(datasets_path, save=True)\n",
    "PhishingData = LoadPrecomputedPhishingDataset(phishing_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Run Experiemnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the experiment itself.\n",
    "We itterate over all datasets and perform retrieval for each query for each model.\n",
    "We then return the score metrics, which are the mean precision, recall, reciprocal rank and time for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPhishingExperiment(dataset: PhishingDataset, \n",
    "                  model_descriptions: dict[str, dict],\n",
    "                  embedding_model_name: str,\n",
    "                  embedding_index_folder_path: str,\n",
    "                  top_k: int,\n",
    "                  test_split: float):\n",
    "    score_metrics: dict[str, dict[str, float]] = {}\n",
    "    queries = getPhishingQueries(dataset)\n",
    "    queries = queries[:int(len(queries)*test_split)]\n",
    "    documents = dataset.GetDocumentDicts()\n",
    "    documents = documents[int(len(queries)*test_split):]\n",
    "    if load_saved_models:\n",
    "        models = loadModels(\"phishing\", model_descriptions)\n",
    "    else:\n",
    "        embedding_index_path = preComputeEmbeddings(\n",
    "                            \"phishing\", \n",
    "                            documents,\n",
    "                            embedding_model_name,\n",
    "                            embedding_index_folder_path)\n",
    "        models: dict[str, Retriever] = createModels(documents=documents, \n",
    "                                dataset_name=\"phishing\", \n",
    "                                models=model_descriptions, \n",
    "                                embedding_index_path=embedding_index_path,\n",
    "                                save=True)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        retrieved_documents = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "        score_metrics[model_name] = {}\n",
    "        total_time = 0\n",
    "        print(f'Computing phishing results for {model_name}')\n",
    "        iter_count = 0\n",
    "        for query_batch in batch(queries, batch_size):\n",
    "            time, retrieved_docs = timeFunction(model.Lookup, \n",
    "                                                **{\"queries\": [query.getQuery() for query in query_batch], \n",
    "                                                \"k\": top_k})\n",
    "            retrieved_documents.extend(retrieved_docs)\n",
    "            total_time += time\n",
    "            iter_count += batch_size\n",
    "            if iter_count % 250 == 0:\n",
    "                print(f'Iter {iter_count}/{len(queries)}')\n",
    "        \n",
    "        retrieved_labels = [[dataset.GetLabelFromId(document.GetId()) for document in query] for query in retrieved_documents]\n",
    "        preds = evaluatePhishingByMajorityVote(retrieved_labels)\n",
    "        labels = [query.getLabel() for query in queries]\n",
    "        \n",
    "        score_metrics[model_name][\"accuracy\"] = calculatePhishingAccuracy(preds, labels)\n",
    "        score_metrics[model_name][\"time\"] = total_time/len(queries)\n",
    "    return score_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retrieval model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\OneDrive\\Skrivebord\\02807_final_project\\CTenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building embedding index using device: cuda. Running this on GPU is strongly adviced!\n",
      "iter: 5000/17904\n",
      "iter: 10000/17904\n",
      "iter: 15000/17904\n",
      "__BuildIndex Elapsed: 353.1629993915558s\n",
      "DPR running on cuda\n",
      "Embedding model is:\n",
      "sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
      "Creating TF-IDF model\n",
      "GetCorpusVocabulary Elapsed: 1.254044532775879s\n",
      "GetInverseDocumentFrequencies Elapsed: 1.556990146636963s\n",
      "GetDocumentsTFIDFVectors Elapsed: 12.727002620697021s\n",
      "Saving model 'TF-IDF' at: models/pickled_models/phishing/TF-IDF.pickle\n",
      "Creating BM25 model\n",
      "GetCorpusVocabulary Elapsed: 1.1569676399230957s\n",
      "GetInverseDocumentFrequencies Elapsed: 1.5650336742401123s\n",
      "GetDocumentLengths Elapsed: 0.449967622756958s\n",
      "GetDocumentBM25Vectors Elapsed: 13.621031284332275s\n",
      "Saving model 'BM25' at: models/pickled_models/phishing/BM25.pickle\n",
      "Creating DPR model\n",
      "Initializing retrieval model!\n",
      "Embedding matrix initialized to cuda!\n",
      "DPR running on cuda\n",
      "Embedding model is:\n",
      "sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
      "Saving model 'DPR' at: models/pickled_models/phishing/DPR.pickle\n",
      "Crossencoder model\n",
      "Initializing retrieval model!\n",
      "Embedding matrix initialized to cuda!\n",
      "DPR running on cuda\n",
      "Embedding model is:\n",
      "sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
      "Saving model 'Crossencoder' at: models/pickled_models/phishing/Crossencoder_n50.pickle\n",
      "KMeans model\n",
      "Initializing retrieval model!\n",
      "Embedding matrix initialized to cuda!\n",
      "KMeans running on: cuda\n",
      "Computing 3 cluster centroids\n",
      "Error difference: 10975.220451921225\n",
      "Error difference: 64.32743111252785\n",
      "Error difference: 17.842753052711487\n",
      "Error difference: 17.4464268386364\n",
      "Error difference: 28.133121341466904\n",
      "Error difference: 25.878419995307922\n",
      "Error difference: 20.897802352905273\n",
      "Error difference: 16.80368885397911\n",
      "Error difference: 8.54700917005539\n",
      "Error difference: 3.503024250268936\n",
      "Error difference: 1.462378829717636\n",
      "Error difference: 0.6868458390235901\n",
      "Error difference: 0.3375326097011566\n",
      "Error difference: 0.28861004114151\n",
      "Error difference: 0.10452127456665039\n",
      "Error difference: 0.030036836862564087\n",
      "Error difference: 0.015232175588607788\n",
      "Error difference: 0.008333951234817505\n",
      "Creating embedding matrices for clusters!\n",
      "Saving model 'KMeans' at: models/pickled_models/phishing/KMeans_k3.pickle\n",
      "CURE model\n",
      "Initializing retrieval model!\n",
      "Embedding matrix initialized to cuda!\n",
      "Created clusters using agglomerative of sizes 2 89 3 2 2 6668 4 8 2 36 2 7 4 1 7 2 44 5 14 3 11 9 1 4 2 1056 4 2 3 2 146 3 1 4 2 6 3 3 2 1 7 9 742 8 3 1 4 1 1 6\n",
      "\n",
      "\n",
      "Time 320.17603278160095 \n",
      "\n",
      "\n",
      "Saving model 'CURE' at: models/pickled_models/phishing/CURE_n25_shrinkage_fraction0.1_threshold0.25_initial_clusters50_subsample_fraction0.5_similarity_measurecosine.pickle\n",
      "Computing phishing results for TF-IDF\n",
      "Iter 250/3730\n",
      "Iter 500/3730\n",
      "Iter 750/3730\n",
      "Iter 1000/3730\n",
      "Iter 1250/3730\n",
      "Iter 1500/3730\n",
      "Iter 1750/3730\n",
      "Iter 2000/3730\n",
      "Iter 2250/3730\n",
      "Iter 2500/3730\n",
      "Iter 2750/3730\n",
      "Iter 3000/3730\n",
      "Iter 3250/3730\n",
      "Iter 3500/3730\n",
      "Iter 3750/3730\n",
      "Computing phishing results for BM25\n",
      "Iter 250/3730\n",
      "Iter 500/3730\n",
      "Iter 750/3730\n",
      "Iter 1000/3730\n",
      "Iter 1250/3730\n",
      "Iter 1500/3730\n",
      "Iter 1750/3730\n",
      "Iter 2000/3730\n",
      "Iter 2250/3730\n",
      "Iter 2500/3730\n",
      "Iter 2750/3730\n",
      "Iter 3000/3730\n",
      "Iter 3250/3730\n",
      "Iter 3500/3730\n",
      "Iter 3750/3730\n",
      "Computing phishing results for DPR\n",
      "Iter 250/3730\n",
      "Iter 500/3730\n",
      "Iter 750/3730\n",
      "Iter 1000/3730\n",
      "Iter 1250/3730\n",
      "Iter 1500/3730\n",
      "Iter 1750/3730\n",
      "Iter 2000/3730\n",
      "Iter 2250/3730\n",
      "Iter 2500/3730\n",
      "Iter 2750/3730\n",
      "Iter 3000/3730\n",
      "Iter 3250/3730\n",
      "Iter 3500/3730\n",
      "Iter 3750/3730\n",
      "Computing phishing results for Crossencoder\n",
      "Iter 250/3730\n"
     ]
    }
   ],
   "source": [
    "score_metrics = runPhishingExperiment(PhishingData, \n",
    "                  model_descriptions,\n",
    "                  embedding_model_name,\n",
    "                  embedding_index_folder_path,\n",
    "                  top_k,\n",
    "                  test_split)\n",
    "print(score_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
