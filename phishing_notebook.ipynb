{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import all necessary helper functions and classes.\n",
    "We also define the device to run the models on (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.phishing import LoadPhishingDataset\n",
    "from models.builers.retriever import Retriever\n",
    "from data.dataloader import DataLoader\n",
    "from models.model_loader_helpers import createModels, loadModels\n",
    "from utils.phishing_utils import getPhishingQueries\n",
    "from models.DPR import DPR\n",
    "from utils.metrics_uitls import timeFunction\n",
    "from utils.phishing_utils import calculatePhishingAccuracy, evaluatePhishingByMajorityVote\n",
    "import configparser\n",
    "import torch\n",
    "import os\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define Experiment Configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the configuration of the experiment.\n",
    "Both the datasets to perform the experiment on and the model configurations.\n",
    "\n",
    "Change the load_saved_models variable to True, to load locally saved models, instead of creating them during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs/config.ini')\n",
    "data_loader = DataLoader(config)\n",
    "\n",
    "model_descriptions = {\"TF-IDF\": {},\n",
    "        \"BM25\": {},\n",
    "        \"DPR\": {},\n",
    "        \"Crossencoder\": {\"n\":25},\n",
    "        \"KMeans\": {\"k\":4},\n",
    "        \"CURE\": {\"k\": 2, \"n\": 2, \"shrinkage_fraction\":0.2}}\n",
    "\n",
    "load_saved_models = False\n",
    "\n",
    "embedding_model_name = \"bert-base-uncased\"\n",
    "embedding_index_folder_path = \"indexes\"\n",
    "\n",
    "top_k = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define Function to Pre-compute Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function helps us reduce a lot of computations, by pre computing the embeddings offline and loading them online, instead of computing them multiple times (one time for each model that relies on embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preComputeEmbeddings(dataset: str, \n",
    "                         documents: list[dict], \n",
    "                         embedding_model_name: str, \n",
    "                         embedding_index_folder_path: str):\n",
    "    embedder = DPR(documents, model_name=embedding_model_name)\n",
    "    embedding_index_path = getPreComputedEmbeddingsPath(dataset, embedding_index_folder_path)\n",
    "    embedder.SaveIndex(embedding_index_path)\n",
    "    return embedding_index_path\n",
    "\n",
    "def getPreComputedEmbeddingsPath(dataset: str, embedding_index_folder_path: str):\n",
    "    return os.path.join(embedding_index_folder_path,dataset,\"embedding_index.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Run Experiemnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the experiment itself.\n",
    "We itterate over all datasets and perform retrieval for each query for each model.\n",
    "We then return the score metrics, which are the mean precision, recall, reciprocal rank and time for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPhishingExperiment( datasets_path: str, \n",
    "                  model_descriptions: dict[str, dict],\n",
    "                  embedding_model_name: str,\n",
    "                  embedding_index_folder_path: str,\n",
    "                  top_k: int):\n",
    "    score_metrics: dict[str, dict[str, float]] = {}\n",
    "    dataset = LoadPhishingDataset(datasets_path)\n",
    "    queries = getPhishingQueries(dataset)\n",
    "    queries = queries[:30]\n",
    "    documents = dataset.GetDocumentDicts()\n",
    "    documents = documents[:25]\n",
    "    if load_saved_models:\n",
    "        models = loadModels(dataset, model_descriptions)\n",
    "    else:\n",
    "        embedding_index_path = preComputeEmbeddings(\n",
    "                            \"phishing\", \n",
    "                            documents,\n",
    "                            embedding_model_name,\n",
    "                            embedding_index_folder_path)\n",
    "        models: dict[str, Retriever] = createModels(documents=documents, \n",
    "                                dataset_name=\"phishing\", \n",
    "                                models=model_descriptions, \n",
    "                                embedding_index_path=embedding_index_path,\n",
    "                                save=True)\n",
    "    for model_name, model in models.items():\n",
    "        preds = []\n",
    "        labels = []\n",
    "        times = []\n",
    "        score_metrics[model_name] = {}\n",
    "        for query in queries:\n",
    "            time, retrieved_documents = timeFunction(model.Lookup, \n",
    "                                                **{\"query\": query.getQuery(), \n",
    "                                                \"k\": top_k})\n",
    "            retrieved_labels = [dataset.GetLabelFromId(document.GetId()) for document in retrieved_documents]\n",
    "            pred = evaluatePhishingByMajorityVote(retrieved_labels)\n",
    "            preds.append(pred)\n",
    "            labels.append(query.getLabel())\n",
    "            times.append(time)\n",
    "        score_metrics[model_name][\"accuracy\"] = calculatePhishingAccuracy(preds, labels)\n",
    "        score_metrics[model_name][\"time\"] = sum(times)/len(times)\n",
    "    return score_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF model\n",
      "GetCorpusVocabulary Elapsed: 0.0011951923370361328s\n",
      "GetInverseDocumentFrequencies Elapsed: 0.002248048782348633s\n",
      "GetDocumentsTFIDFVectors Elapsed: 0.00797414779663086s\n",
      "Saving model 'TF-IDF' at: models/pickled_models/phishing/TF-IDF.pickle\n",
      "Creating BM25 model\n",
      "GetCorpusVocabulary Elapsed: 0.0007119178771972656s\n",
      "GetInverseDocumentFrequencies Elapsed: 0.0019381046295166016s\n",
      "GetDocumentLengths Elapsed: 0.0003120899200439453s\n",
      "GetDocumentBM25Vectors Elapsed: 0.007869958877563477s\n",
      "Saving model 'BM25' at: models/pickled_models/phishing/BM25.pickle\n",
      "Creating DPR model\n",
      "Saving model 'DPR' at: models/pickled_models/phishing/DPR.pickle\n",
      "Crossencoder model\n",
      "Saving model 'Crossencoder' at: models/pickled_models/phishing/Crossencoder_n25.pickle\n",
      "KMeans model\n",
      "Saving model 'KMeans' at: models/pickled_models/phishing/KMeans_k4.pickle\n",
      "CURE model\n",
      "Saving model 'CURE' at: models/pickled_models/phishing/CURE_k2_n2_shrinkage_fraction0.2.pickle\n",
      "QueryToVector Elapsed: 0.004414081573486328s\n",
      "CalculateScores Elapsed: 0.005627155303955078s\n",
      "QueryToVector Elapsed: 0.0001590251922607422s\n",
      "CalculateScores Elapsed: 0.00025200843811035156s\n",
      "QueryToVector Elapsed: 0.00020313262939453125s\n",
      "CalculateScores Elapsed: 0.0002880096435546875s\n",
      "QueryToVector Elapsed: 0.00015997886657714844s\n",
      "CalculateScores Elapsed: 0.0002448558807373047s\n",
      "QueryToVector Elapsed: 0.00013017654418945312s\n",
      "CalculateScores Elapsed: 0.00020813941955566406s\n",
      "QueryToVector Elapsed: 0.0004837512969970703s\n",
      "CalculateScores Elapsed: 0.0005738735198974609s\n",
      "QueryToVector Elapsed: 0.0002200603485107422s\n",
      "CalculateScores Elapsed: 0.0003020763397216797s\n",
      "QueryToVector Elapsed: 0.001157999038696289s\n",
      "CalculateScores Elapsed: 0.0012710094451904297s\n",
      "QueryToVector Elapsed: 0.00016570091247558594s\n",
      "CalculateScores Elapsed: 0.0002548694610595703s\n",
      "QueryToVector Elapsed: 0.0003287792205810547s\n",
      "CalculateScores Elapsed: 0.00041604042053222656s\n",
      "QueryToVector Elapsed: 0.00030422210693359375s\n",
      "CalculateScores Elapsed: 0.0003910064697265625s\n",
      "QueryToVector Elapsed: 3.910064697265625e-05s\n",
      "CalculateScores Elapsed: 0.00011682510375976562s\n",
      "QueryToVector Elapsed: 0.0008940696716308594s\n",
      "CalculateScores Elapsed: 0.000993967056274414s\n",
      "QueryToVector Elapsed: 0.00020599365234375s\n",
      "CalculateScores Elapsed: 0.0002911090850830078s\n",
      "QueryToVector Elapsed: 0.0004291534423828125s\n",
      "CalculateScores Elapsed: 0.0005211830139160156s\n",
      "QueryToVector Elapsed: 0.00010991096496582031s\n",
      "CalculateScores Elapsed: 0.00020885467529296875s\n",
      "QueryToVector Elapsed: 0.00013899803161621094s\n",
      "CalculateScores Elapsed: 0.00023174285888671875s\n",
      "QueryToVector Elapsed: 0.00024008750915527344s\n",
      "CalculateScores Elapsed: 0.0003261566162109375s\n",
      "QueryToVector Elapsed: 0.0002968311309814453s\n",
      "CalculateScores Elapsed: 0.00038886070251464844s\n",
      "QueryToVector Elapsed: 0.001317739486694336s\n",
      "CalculateScores Elapsed: 0.0014219284057617188s\n",
      "QueryToVector Elapsed: 0.00020194053649902344s\n",
      "CalculateScores Elapsed: 0.00029206275939941406s\n",
      "QueryToVector Elapsed: 9.274482727050781e-05s\n",
      "CalculateScores Elapsed: 0.0001747608184814453s\n",
      "QueryToVector Elapsed: 0.0001652240753173828s\n",
      "CalculateScores Elapsed: 0.0002560615539550781s\n",
      "QueryToVector Elapsed: 3.314018249511719e-05s\n",
      "CalculateScores Elapsed: 0.00011396408081054688s\n",
      "QueryToVector Elapsed: 6.222724914550781e-05s\n",
      "CalculateScores Elapsed: 0.00013709068298339844s\n",
      "QueryToVector Elapsed: 0.00011086463928222656s\n",
      "CalculateScores Elapsed: 0.00018906593322753906s\n",
      "QueryToVector Elapsed: 5.626678466796875e-05s\n",
      "CalculateScores Elapsed: 0.00014019012451171875s\n",
      "QueryToVector Elapsed: 0.0002911090850830078s\n",
      "CalculateScores Elapsed: 0.0003750324249267578s\n",
      "QueryToVector Elapsed: 0.0001380443572998047s\n",
      "CalculateScores Elapsed: 0.00021719932556152344s\n",
      "QueryToVector Elapsed: 8.082389831542969e-05s\n",
      "CalculateScores Elapsed: 0.0001590251922607422s\n",
      "QueryToVector Elapsed: 0.0002601146697998047s\n",
      "CalculateScores Elapsed: 0.0003647804260253906s\n",
      "QueryToVector Elapsed: 0.00011682510375976562s\n",
      "CalculateScores Elapsed: 0.00019407272338867188s\n",
      "QueryToVector Elapsed: 0.00017786026000976562s\n",
      "CalculateScores Elapsed: 0.0002608299255371094s\n",
      "QueryToVector Elapsed: 0.0001468658447265625s\n",
      "CalculateScores Elapsed: 0.00022602081298828125s\n",
      "QueryToVector Elapsed: 0.00012803077697753906s\n",
      "CalculateScores Elapsed: 0.00020194053649902344s\n",
      "QueryToVector Elapsed: 0.0004429817199707031s\n",
      "CalculateScores Elapsed: 0.0005280971527099609s\n",
      "QueryToVector Elapsed: 0.0002009868621826172s\n",
      "CalculateScores Elapsed: 0.0002789497375488281s\n",
      "QueryToVector Elapsed: 0.0010578632354736328s\n",
      "CalculateScores Elapsed: 0.0011479854583740234s\n",
      "QueryToVector Elapsed: 0.00014901161193847656s\n",
      "CalculateScores Elapsed: 0.0002281665802001953s\n",
      "QueryToVector Elapsed: 0.00030922889709472656s\n",
      "CalculateScores Elapsed: 0.0004019737243652344s\n",
      "QueryToVector Elapsed: 0.0002932548522949219s\n",
      "CalculateScores Elapsed: 0.0003731250762939453s\n",
      "QueryToVector Elapsed: 3.409385681152344e-05s\n",
      "CalculateScores Elapsed: 0.00011110305786132812s\n",
      "QueryToVector Elapsed: 0.0009291172027587891s\n",
      "CalculateScores Elapsed: 0.0010221004486083984s\n",
      "QueryToVector Elapsed: 0.00020766258239746094s\n",
      "CalculateScores Elapsed: 0.0002868175506591797s\n",
      "QueryToVector Elapsed: 0.0004169940948486328s\n",
      "CalculateScores Elapsed: 0.0005009174346923828s\n",
      "QueryToVector Elapsed: 9.703636169433594e-05s\n",
      "CalculateScores Elapsed: 0.00017309188842773438s\n",
      "QueryToVector Elapsed: 0.00011110305786132812s\n",
      "CalculateScores Elapsed: 0.00018715858459472656s\n",
      "QueryToVector Elapsed: 0.00021982192993164062s\n",
      "CalculateScores Elapsed: 0.0002980232238769531s\n",
      "QueryToVector Elapsed: 0.0002627372741699219s\n",
      "CalculateScores Elapsed: 0.0003409385681152344s\n",
      "QueryToVector Elapsed: 0.0011768341064453125s\n",
      "CalculateScores Elapsed: 0.0012698173522949219s\n",
      "QueryToVector Elapsed: 0.00018787384033203125s\n",
      "CalculateScores Elapsed: 0.0002682209014892578s\n",
      "QueryToVector Elapsed: 9.202957153320312e-05s\n",
      "CalculateScores Elapsed: 0.00016498565673828125s\n",
      "QueryToVector Elapsed: 0.00016498565673828125s\n",
      "CalculateScores Elapsed: 0.00024318695068359375s\n",
      "QueryToVector Elapsed: 4.100799560546875e-05s\n",
      "CalculateScores Elapsed: 0.00011396408081054688s\n",
      "QueryToVector Elapsed: 5.507469177246094e-05s\n",
      "CalculateScores Elapsed: 0.000125885009765625s\n",
      "QueryToVector Elapsed: 0.00011205673217773438s\n",
      "CalculateScores Elapsed: 0.0001881122589111328s\n",
      "QueryToVector Elapsed: 5.1975250244140625e-05s\n",
      "CalculateScores Elapsed: 0.000125885009765625s\n",
      "QueryToVector Elapsed: 0.0002849102020263672s\n",
      "CalculateScores Elapsed: 0.00037097930908203125s\n",
      "QueryToVector Elapsed: 0.0001399517059326172s\n",
      "CalculateScores Elapsed: 0.00022029876708984375s\n",
      "QueryToVector Elapsed: 8.273124694824219e-05s\n",
      "CalculateScores Elapsed: 0.00015783309936523438s\n",
      "{'TF-IDF': {'accuracy': 0.7333333333333333, 'time': 0.0005544153333175928}, 'BM25': {'accuracy': 0.7333333333333333, 'time': 0.00035261949960840866}, 'DPR': {'accuracy': 0.7333333333333333, 'time': 0.07487313200011461}, 'Crossencoder': {'accuracy': 0.7333333333333333, 'time': 11.139255959699707}, 'KMeans': {'accuracy': 0.8, 'time': 0.07477258190095502}, 'CURE': {'accuracy': 0.7333333333333333, 'time': 0.07239687906791611}}\n"
     ]
    }
   ],
   "source": [
    "score_metrics = runPhishingExperiment(\"datasets/Phishing_Email.csv\", \n",
    "                  model_descriptions,\n",
    "                  embedding_model_name,\n",
    "                  embedding_index_folder_path,\n",
    "                  top_k)\n",
    "print(score_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
