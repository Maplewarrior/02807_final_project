{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset from data/datasets\\fiqa\n",
      "data/datasets\\fiqa\\corpus.jsonl\n"
     ]
    }
   ],
   "source": [
    "from data.dataloader import Data\n",
    "import configparser\n",
    "# load config.ini \n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "dat = Data(config)\n",
    "corpus, queries = dat.get_dataset('fiqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '3', 'title': '', 'text': \"I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.\", 'metadata': {}}\n",
      "{'_id': '0', 'text': 'What is considered a business expense on a business trip?', 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])\n",
    "print(queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists in /Users/andreasbigom/Documents/dtu/computational_tools/02807_final_project/datasets/nfcorpus\n"
     ]
    }
   ],
   "source": [
    "from data.query import Query\n",
    "from helper_functions import DownloadData, LoadData, LoadQueries, LoadRelevants\n",
    "\n",
    "DownloadData()\n",
    "data = LoadData()\n",
    "queries = LoadQueries()\n",
    "\n",
    "relevants_raw = LoadRelevants()\n",
    "relevants: dict[str, list] = {}\n",
    "for row in relevants_raw.iloc:\n",
    "    query_id = row[\"query-id\"]\n",
    "    corpus_id = row[\"corpus-id\"]\n",
    "    if not query_id in relevants.keys():\n",
    "        relevants[query_id] = []\n",
    "    relevants[query_id].append(corpus_id)\n",
    "\n",
    "documents = [{\"title\": row[\"title\"], \"text\": row[\"text\"], \"id\": row[\"_id\"]} for row in data.iloc]\n",
    "queries = {row[\"_id\"]: Query(text = row[\"text\"], id = row[\"_id\"], relevant_document_ids=relevants[row[\"_id\"]]) for row in queries.iloc if row[\"_id\"] in relevants.keys()}"
    "# documents = [\n",
    "#     {\"text\": \"A cat is an animal.\", \"_id\": 1},\n",
    "#     {\"text\": \"A dog is a house animal.\", \"_id\": 1},\n",
    "#     {\"text\": \"The city of new york is big.\", \"_id\": 2},\n",
    "#     {\"text\": \"The city of chicago is big.\", \"_id\": 3},\n",
    "#     {\"text\": \"The city of gentofte is big.\", \"_id\": 4},\n",
    "#     {\"text\": \"The city of copenhagen is big.\", \"_id\": 5},\n",
    "#     {\"text\": \"During the cold war, many comunists were crazy.\", \"_id\": 5},\n",
    "#     {\"text\": \"Are there any better movie than The Godfather?\", \"_id\": 5}\n",
    "#     ]\n",
    "\n",
    "# Just for testing\n",
    "documents = corpus[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bm25 import BM25\n",
    "from models.builers.retriever import Retriever\n",
    "from models.CURE import CURE\n",
    "from models.k_means import KMeans\n",
    "from models.TFIDF import TFIDF\n",
    "from models.BM25 import BM25\n",
    "from models.DPR import DPR\n",
    "from models.DPR_crossencoder import DPRCrossencoder\n",
    "\n",
    "models: dict[str: Retriever] = {\n",
    "    \"TF-IDF\": TFIDF(documents=documents),\n",
    "    # \"DPR\": DPR(documents=documents),\n",
    "    # \"Crossencoder\": DPRCrossencoder(documents=documents, n=25),\n",
    "    # \"KMeans\": KMeans(documents=documents, k = 4),\n",
    "    # \"CURE\": CURE(documents=documents, k = 2, n=2, shrinkage_fraction=0.2),\n",
    "    #  \"BM25\": BM25(documents=documents),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def TimeFunction(function, **args):\n",
    "    time_before = time.perf_counter()\n",
    "    output = function(**args)\n",
    "    time_after = time.perf_counter()\n",
    "    return time_after - time_before, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieveQueryAndGetScore(model: Retriever, query: Query, k: int):\n",
    "    retrieved_documents = model.Lookup(query=query.GetQuery(), k=k)\n",
    "    relevancies = []\n",
    "    for document in retrieved_documents:\n",
    "        if query.IsDocumentRelevant(document):\n",
    "            relevancies.append(True)\n",
    "        else:\n",
    "            relevancies.append(False)\n",
    "    return relevancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanReciprocalRank(relevancies):\n",
    "    for i, relevancy in enumerate(relevancies):\n",
    "        if relevancy:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "def Precision(relevancies):\n",
    "    return sum([1 if relevancy else 0 for relevancy in relevancies]) / len(relevancies)\n",
    "\n",
    "def Recall(relevancies, query: Query):\n",
    "    return sum([1 if relevancy else 0 for relevancy in relevancies]) / min(len(relevancies), query.GetNumberOfRelevantDocuments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001147707982454449\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from data.document import Document\n",
    "\n",
    "query = \"The aims of this study were to determine the concentrations of 4-nonylphenol (NP)\"\n",
    "k = 10\n",
    "\n",
    "for model_type in models.keys():\n",
    "    model: Retriever = models[model_type]\n",
    "    time_perf, relevancies = TimeFunction(RetrieveQueryAndGetScore, **{\"model\": model, \"query\": queries['PLAIN-3'], \"k\": k})\n",
    "    print(time_perf)\n",
    "    print(MeanReciprocalRank(relevancies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
