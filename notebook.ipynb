{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.builers.retriever import Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset from data/datasets\\fiqa\n",
      "data/datasets\\fiqa\\corpus.jsonl\n"
     ]
    }
   ],
   "source": [
    "from data.dataloader import Data\n",
    "import configparser\n",
    "\n",
    "# load config.ini \n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "data_handler = Data(config)\n",
    "dataset = \"fiqa\"\n",
    "corpus, queries = data_handler.get_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 relevants from the dictionary\n",
      "   0 : [('18850', 1)]\n",
      "   4 : [('196463', 1)]\n",
      "   5 : [('69306', 1)]\n",
      "   6 : [('560251', 1), ('188530', 1), ('564488', 1)]\n",
      "   7 : [('411063', 1)]\n",
      "\n",
      "First query and document from corpus:\n",
      "  Corpus[0]:   {'_id': '3', 'title': '', 'text': \"I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.\", 'metadata': {}}\n",
      "  Query[0]:  {'_id': '0', 'text': 'What is considered a business expense on a business trip?', 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "relevants = data_handler.get_relevants(dataset)\n",
    "# print first 5 relevants from the dictionary\n",
    "print(\"First 5 relevants from the dictionary\")\n",
    "for i in list(relevants.keys())[:5]:\n",
    "    print(\"  \", i, \":\", relevants[i])\n",
    "\n",
    "print(\"\\nFirst query and document from corpus:\")\n",
    "print(\"  Corpus[0]:  \", corpus[0])\n",
    "print(\"  Query[0]: \", queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.model_loader_helpers import create_models\n",
    "\n",
    "# models_to_create = {\"TF-IDF\": {},\n",
    "#                     \"BM25\": {},\n",
    "#                     \"DPR\": {},\n",
    "#                     \"Crossencoder\": {\"n\":25},\n",
    "#                     \"KMeans\": {\"k\":4},\n",
    "#                     \"CURE\": {\"k\": 2, \"n\": 2, \"shrinkage_fraction\":0.2}}\n",
    "\n",
    "# create_models(documents=documents, dataset_name=dataset, models=models_to_create, save=True)\n",
    "\n",
    "from models.model_loader_helpers import load_models\n",
    "\n",
    "models_to_load = {\"TF-IDF\": {},\n",
    "                    \"BM25\": {},\n",
    "                    \"DPR\": {}}\n",
    "models = load_models(\"fiqa\", models_to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is considered a business expense on a business trip?', 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.query import Query\n",
    "\n",
    "queries_ = data_handler.get_queries() # Get queries in the correct format\n",
    "queries = []\n",
    "for rel in relevants.items():\n",
    "    id = rel[0]\n",
    "    rels = [r[0] for r in rel[1]]\n",
    "    query = queries_[id]\n",
    "    queries.append(Query(text=query['text'], id=id, relevant_document_ids=rels))\n",
    "\n",
    "# output an example\n",
    "queries[0].GetQuery(), queries[0].GetNumberOfRelevantDocuments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanReciprocalRank(relevancies):\n",
    "    for i, relevancy in enumerate(relevancies):\n",
    "        if relevancy:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "def Precision(relevancies):\n",
    "    return sum([1 if relevancy else 0 for relevancy in relevancies]) / len(relevancies)\n",
    "\n",
    "def Recall(relevancies, query: Query):\n",
    "    return sum([1 if relevancy else 0 for relevancy in relevancies]) / min(len(relevancies), query.GetNumberOfRelevantDocuments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def TimeFunction(function, **args):\n",
    "    time_before = time.perf_counter()\n",
    "    output = function(**args)\n",
    "    time_after = time.perf_counter()\n",
    "    return time_after - time_before, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieveQueryAndGetScore(model: Retriever, query: Query, k: int):\n",
    "    retrieved_documents = model.Lookup(query=query.GetQuery(), k=k)\n",
    "    relevancies = []\n",
    "    for document in retrieved_documents:\n",
    "        if query.IsDocumentRelevant(document):\n",
    "            relevancies.append(True)\n",
    "        else:\n",
    "            relevancies.append(False)\n",
    "    return relevancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanReciprocalRank(relevancies):\n",
    "    for i, relevancy in enumerate(relevancies):\n",
    "        if relevancy:\n",
    "            return 1/(i+1)\n",
    "    return 0\n",
    "\n",
    "def Precision(relevancies):\n",
    "    return sum([1 if relevancy else 0 for relevancy in relevancies]) / len(relevancies)\n",
    "\n",
    "def Recall(relevancies, query: Query):\n",
    "    return sum([1 if relevancy else 0 for relevancy in relevancies]) / min(len(relevancies), query.GetNumberOfRelevantDocuments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What is considered a business expense on a business trip?\n",
      "TF-IDF\n",
      "   0.00015629990957677364 s\n",
      "   0 (MRR)\n",
      "   0.0 (Precision)\n",
      "   0.0 (Recall)\n",
      "BM25\n",
      "   0.00010780012235045433 s\n",
      "   0 (MRR)\n",
      "   0.0 (Precision)\n",
      "   0.0 (Recall)\n",
      "DPR\n",
      "   0.09074080013670027 s\n",
      "   0 (MRR)\n",
      "   0.0 (Precision)\n",
      "   0.0 (Recall)\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "print(\"Query: \", queries[0].GetQuery())\n",
    "\n",
    "for model_type in models.keys():\n",
    "    query = queries[0]\n",
    "    k = query.GetNumberOfRelevantDocuments()\n",
    "    print(model_type)\n",
    "    model: Retriever = models[model_type]\n",
    "    time_perf, relevancies = TimeFunction(RetrieveQueryAndGetScore, **{\"model\": model, \"query\": queries[0], \"k\": k})\n",
    "    print(\"  \", time_perf, \"s\")\n",
    "    print(\"  \", MeanReciprocalRank(relevancies), \"(MRR)\")\n",
    "    print(\"  \", Precision(relevancies), \"(Precision)\")\n",
    "    print(\"  \", Recall(relevancies, query), \"(Recall)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
